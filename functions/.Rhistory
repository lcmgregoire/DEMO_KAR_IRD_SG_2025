for (i in 1:nrow(new.lc)) {
r.ind <- which(meta.d$unit == new.lc$unit[i])
if (length(r.ind) == 0) next
new.lc$genotype[i] <- unique(meta.d$Genotype[r.ind])
new.lc$g_alias[i] <- unique(meta.d$G..Alias[r.ind])
new.lc$treatment[i] <- unique(meta.d$Treatment[r.ind])
if (i %% 100 == 0) cat("row : ", i, "\n")  # avoid froze screen
}
load(file = paste0(path, "./data/m.lc.RData"))
fdt <- readline(prompt = "Enter FIRST DATE of experiment (required format: YYYY-MM-DD): ") #day after depot on Lc  2025-05-20
firstDate=as.Date(as.character(fdt))
# NOTE 1:  the next steps will "cut" this day of measurement
ldt <- readline(prompt = "Enter LAST DATE of experiment (required format: YYYY-MM-DD): ") # example  2025-06-09
lastDate=as.Date(as.character(ldt))
avg_wgt <- readline(prompt = "Enter an expected weight, in g, just a rough estimate: ") # example 4200
avg_wgt=as.numeric(avg_wgt)
cat("The expected weight on a loadcell is roughly : ",avg_wgt, "g ")
## Irrigation dates
print("Enter irrigation days. See comments for more info")
# NOTE 1: Enter date(s) of irrigation or when data is extremely noisy.
# NOTE 2: If no such date, enter LAST DATE of experiment
# NOTE 3: The entire date will be erased: in the case of evening irrigation, it may not be necessary to erase the entire date. This will depend on the quantity and quality of your data.
irrg.dts <- readline(prompt = "Enter irrigation days (required format : c(YYYY-MM-DD, ... ) : ")
#EXEMPLE CANOPY VS IND :
# c("2025-06-09 ")
irrg.dts <- gsub('c\\(\\"|\\")', '', irrg.dts)
cat("The irrigation days or noisy days that need to be removed are :"  ,irrg.dts, "(or last day of experience if none)")
# remove 'c('  ')' "" \
irrg.dts <- gsub("^c\\(|\\)$", "", irrg.dts)
irrg.dts <- gsub("\"", "", irrg.dts)
irrg.dts <- gsub(" ", "", irrg.dts)
irrg.dts <- unlist(strsplit(irrg.dts, split = ","))
irrg.dts <- as.Date(irrg.dts)
irrg.dts
## Date 1 and 2 : format "YYYY-MM-DD HH:MM:SS"
Date1 = paste(as.character(firstDate) , "00:00:00")
Date2 = paste(as.character(lastDate), "23:30:00")
Date1<-ymd_hms(Date1)
Date2<-ymd_hms(Date2)
Date1
Date2
dates <- seq(Date1, Date2, by="15 mins")
print("The format should be YYYY-MM-DD HH:MM:SS UTC. Is it correct?")
### Create Climate data ###
print("Load climatic data. They differ according to the measurement platforms (IRD/ICRISAT). More information in comments")
# NOTE 1 : On the ICRISAT platform, we have climatic data from various sensors that are not adapted to the 15min format, such as LC weighings. The first step is therefore to adapt these data to the 15-minute format, and to merge the data from several sensors into a single dataframe.
#  In the case of another platform such as IRD PLATFORM, this problem is absent.
platform <- readline(prompt = "What platform are you using ? Required : IRD or ICRISAT  : ")
if ((platform ==  "ICRISAT") == TRUE) {
m_lc_file_path
clm.df <- read.csv(climate_file_path)
sensor.unit.df <- read.csv(sensor_file_path)
clm.df.mapped <- clm.df[clm.df$sensor %in% sensor.unit.df$sensor, ]
unq.clm.var <- unique(clm.df.mapped$variable)
# "Temperature (Deg C)" : unq.clm.var[1]
temperature.DF <-  subset(clm.df.mapped, variable == unq.clm.var[1])
temperature.DF$timestamp = ymd_hms(temperature.DF$timestamp)
temperature.DF$timestamp <-   floor_date(temperature.DF$timestamp , "15 minutes")
# create empty dataframe to store all values
temp_df =   as.data.frame(matrix(nrow = length(unique(temperature.DF$timestamp)),
ncol = 2))
colnames(temp_df) =c("value","timestamp")
temp_df$value = as.numeric(temp_df$value)
temp_df$timestamp = as.POSIXct(temp_df$value)
for (i in 1:length( unique(temperature.DF$timestamp))) {
subset_timestamp =  subset(temperature.DF, timestamp == unique(temperature.DF$timestamp)[i])
#### some outliers in the data : negative value
subset_timestamp[subset_timestamp < 0] <- NA
subset_timestamp = na.omit(subset_timestamp)
subset_timestamp_avg =  subset_timestamp %>%
summarise(value = mean(value))
subset_timestamp_avg$timestamp = as.POSIXct(unique(temperature.DF$timestamp)[i])
temp_df[i,] = subset_timestamp_avg
}
# "Relative Humidity (%)" :unq.clm.var[2]
RH.DF <-  subset(clm.df.mapped, variable == unq.clm.var[2])
RH.DF$timestamp = ymd_hms(RH.DF$timestamp)
RH.DF$timestamp <-   floor_date(RH.DF$timestamp , "15 minutes")
# create empty dataframe to store all values
RH_df =   as.data.frame(matrix(nrow = length(unique(RH.DF$timestamp)),
ncol = 2))
colnames(RH_df) =c("value","timestamp")
RH_df$value = as.numeric(RH_df$value)
RH_df$timestamp = as.POSIXct(RH_df$value)
for (i in 1:length( unique(RH.DF$timestamp))) {
subset_timestamp =  subset(RH.DF, timestamp == unique(RH.DF$timestamp)[i])
#### some outliers in the data : negative value
subset_timestamp[subset_timestamp < 0] <- NA
subset_timestamp = na.omit(subset_timestamp)
subset_timestamp_avg =  subset_timestamp %>%
summarise(value = mean(value))
subset_timestamp_avg$timestamp = as.POSIXct(unique(RH.DF$timestamp)[i])
RH_df[i,] = subset_timestamp_avg
}
# "Flux Density (W/m^2)" : unq.clm.var[4]
SR.DF <-  subset(clm.df.mapped, variable == unq.clm.var[4])
SR.DF$timestamp = ymd_hms(SR.DF$timestamp)
SR.DF$timestamp <-   floor_date(SR.DF$timestamp , "15 minutes")
# create empty dataframe to store all values
SR_df =   as.data.frame(matrix(nrow = length(unique(SR.DF$timestamp)),
ncol = 2))
colnames(SR_df) =c("value","timestamp")
SR_df$value = as.numeric(SR_df$value)
SR_df$timestamp = as.POSIXct(SR_df$value)
for (i in 1:length( unique(SR.DF$timestamp))) {
subset_timestamp =  subset(SR.DF, timestamp == unique(SR.DF$timestamp)[i])
#### some outliers in the data : negative value
subset_timestamp[subset_timestamp < 0] <- NA
subset_timestamp = na.omit(subset_timestamp)
subset_timestamp_avg =  subset_timestamp %>%
summarise(value = mean(value))
subset_timestamp_avg$timestamp = as.POSIXct(unique(SR.DF$timestamp)[i])
SR_df[i,] = subset_timestamp_avg
}
# "Windspeed (meters/second)" :unq.clm.var[5]
WS.DF <-  subset(clm.df.mapped, variable == unq.clm.var[5])
WS.DF$timestamp = ymd_hms(WS.DF$timestamp)
WS.DF$timestamp <-   floor_date(WS.DF$timestamp , "15 minutes")
# create empty dataframe to store all values
WS_df =   as.data.frame(matrix(nrow = length(unique(WS.DF$timestamp)),
ncol = 2))
colnames(WS_df) =c("value","timestamp")
WS_df$value = as.numeric(WS_df$value)
WS_df$timestamp = as.POSIXct(WS_df$value)
for (i in 1:length( unique(WS.DF$timestamp))) {
subset_timestamp =  subset(WS.DF, timestamp == unique(WS.DF$timestamp)[i])
#### some outliers in the data : negative value
subset_timestamp[subset_timestamp < 0] <- NA
subset_timestamp = na.omit(subset_timestamp)
subset_timestamp_avg =  subset_timestamp %>%
summarise(value = mean(value))
subset_timestamp_avg$timestamp = as.POSIXct(unique(WS.DF$timestamp)[i])
WS_df[i,] = subset_timestamp_avg
}
temp_df$timestamp <- as.POSIXct(temp_df$timestamp, tz = "UTC")
RH_df$timestamp <- as.POSIXct(RH_df$timestamp, tz = "UTC")
SR_df$timestamp <- as.POSIXct(SR_df$timestamp,tz = "UTC")
WS_df$timestamp <- as.POSIXct(WS_df$timestamp, tz = "UTC")
names(temp_df)[names(temp_df) == "value"] <- "Temp"
names(RH_df)[names(RH_df) == "value"] <- "RH"
names(SR_df)[names(SR_df) == "value"] <- "SR"
names(WS_df)[names(WS_df) == "value"] <- "WS"
dfs <- list(temp_df, RH_df, SR_df, WS_df)
lapply(dfs, function(df) names(df))  #check colnames before merge
lapply(dfs, function(df) class(df$timestamp))  # check class before merge
sapply(dfs, nrow)
weather12 <- merge(dfs[[1]], dfs[[2]], by = "timestamp", all = TRUE)
weather123 <- merge(weather12, dfs[[3]], by = "timestamp", all = TRUE)
weather <- merge(weather123, dfs[[4]], by = "timestamp", all = TRUE)
## add date and VPD col
weather$Date = date(weather$timestamp)
weather <- weather[, c("Date", setdiff(names(weather), "Date"))]
weather$VPD = NA
names(weather)[names(weather) == "timestamp"] <- "TS"
weather <- weather[, c("Date", "TS", "Temp", "RH", "VPD", "SR", "WS")]
write.table(weather, file = "weather_data_sowing_to_harvest.csv", sep = ";", dec = ".", row.names = F)
# Subset weather data only for time experiment #
weather <- subset(weather, TS %in% dates)
weather <- weather[!as.Date(weather$Date) %in% irrg.dts, ]
# remove row of LC dataframe out of measurmeent period
## need that timestamp of dates and LC fitted
write.table(weather, file = "climate_raw.csv", sep = ";", dec = ".", row.names = F)
clm.n =  weather
## weather s'arrete au 2025-03-12 11:00:00 mais poids continue jusqu'a 23:30
# donc TS = 1293 et ce n'est pas problematique
nrow(weather)
}
if ((platform ==  "IRD") == TRUE) {
# clm.n <- read.csv(paste0(path, climate_file), sep = ";", dec = ".")
clm.n <- read.csv(climate_file_path, sep = ";", dec = ".")
clm.n <- clm.n[,1:7]
clm.n$Date <- dmy(clm.n$Date)
clm.n$TS <- ifelse(grepl("^\\d{2}:\\d{2}$", clm.n$TS), paste0(clm.n$TS, ":00"), clm.n$TS)
# clm.n$TS <- as.POSIXct(clm.n$TS)
clm.n$RH <- as.numeric(substr(clm.n$RH, 1, 2))
}
str(clm.n)
print("Regardless of the source of climate data, the result here should be : Date (YYYY-MM-DD),TS (POSIXct or hms),Temp (num),RH (num),VPD (empty) ,SR (num),WS(num). Is it good? ")
write.csv(clm.n, paste0(path, "./data/climate.csv"))
save(clm.n, file = paste0(path, "./data/climate.RData"))
load(file = paste0(path, "./data/climate.RData"))
allData <- list(m.lc = m.lc, meta.d = meta.d, climate = clm.n)
planimeter_data <- readline(prompt = "Do you have planimeter data to integrate? Required YES or NO  : ")
if ((planimeter_data == "YES")==TRUE) {
planimeter_file_path = paste0(path,planimeter_file)
planimeter_file_path = gsub('/\".', '',planimeter_file_path )
planimeter_file_path = gsub('\"','',planimeter_file_path )
final_LA <- read.csv(planimeter_file_path, sep = ";")
allData <- list(m.lc = m.lc, meta.d = meta.d, climate = clm.n, final_LA = final_LA )
}
save(allData, file = paste0(path, "./data/allData.RData"))
load(file = paste0(path, "./data/allData.RData"))
planteye_save <- readline(prompt = "Do you have PlantEye data to integrate? Required YES or NO  : ")
if ((planteye_save == "YES")==TRUE) {
PE_file_path = paste0(path,PE_file)
PE_file_path = gsub('/\".', '',PE_file_path )
PE_file_path = gsub('\"','',PE_file_path )
design_file_path = paste0(path,design_file)
design_file_path = gsub('/\".', '',design_file_path )
design_file_path = gsub('\"','',design_file_path )
pe.df <- read.csv(PE_file_path)
d_exp <- read.csv(design_file_path)
if ((planteye_save == "NO") == TRUE) {
allData <- list(m.lc = m.lc, meta.d = meta.d, climate = clm.n,
sensor.unit.df = sensor.unit.df) }
if ((planteye_save == "YES") == TRUE) {
allData <- list(m.lc = m.lc, meta.d = meta.d, climate = clm.n,
sensor.unit.df = sensor.unit.df, pe.df = pe.df,  final_LA = final_LA, d-exp) }
}
save(allData, file = paste0(path, "./data/allData.RData"))
load(file = paste0(path, "./data/allData.RData"))
print("Stage-I: Process LC data and generate ETr matrix")
st.time <- Sys.time()
#### Prepare the LC data and meta data
print("Load  and prepare input data")
load("./data/allData.RData")
## remove from beggining irrigation dates
m.lc = allData$m.lc
m.lc$Date = as.Date(m.lc$timestamp)
m.lc <- m.lc[!as.Date(m.lc$Date) %in% irrg.dts, ]
# remove row of LC dataframe out of measurmeent period
## need that timestamp of dates and LC fitted
dates = as.POSIXct(dates)
m.lc$timestamp <- floor_date(m.lc$timestamp, unit = "minute")
m.lc$timestamp = as.POSIXct(m.lc$timestamp)
m.lc <- subset(m.lc, m.lc$timestamp %in% dates)
nrow(m.lc)
meta.d <- allData$meta.d # Get Genotype and Exp design metadata
species.nm <- unique(meta.d$Species) # Get the list of species from the metadata
meta.d.sp <- meta.d[meta.d$Species==species.nm[1], ] # Include the species ID e.g. 1 for 'Sorghum' as per the data
noEntrySecs <- which(!unique(m.lc$unit) %in% unique(meta.d.sp$unit)) # Find sectors with missing metadata
noEntrySecNms <- unique(m.lc$unit)[noEntrySecs]
m.lc <- m.lc[! m.lc$unit %in% noEntrySecNms, ] # Remove sectors-without-metadata from original loadcells file
# Extract matrix of loadcell data
LC.MAT.OP <- extractRawLCmatrix(x = m.lc, y = meta.d.sp,
s=firstDate, z = lastDate,
inter = seq_by)
LC.MAT.f <- LC.MAT.OP$LC.MAT.f
load( file = paste(opPATH.obj, "LC.MAT.f.RData", sep = ""))
load( file = paste(opPATH.obj, "LC.MAT.TSinfo.RData", sep = ""))
TS = LC.MAT.f$TS # timestamp without irrigation during measurement period
length(TS) # umbre of measurement in timestamp
nrow(LC.MAT.TSinfo)# nb LC
print("outlier WEIGHT detection BEFORE filtering")
check_for_negative_values(LC.MAT.f)
max_df=as.data.frame(colMax(LC.MAT.f)) ### LC.MAT.f can contain outliers weights
max(max_df[6:nrow(max_df),]) #is this a possible weight (in grams)?
print("Dataset (LC.MAT.f) can contain negative weights and outliers weights")
print("Plot the raw weights")
weight_profile_output = draw_weight_raw(data=LC.MAT.f)
# Add metadata to LC matrix :
meta.d.LCmat <- meta.d.sp[
meta.d.sp$unit %in% colnames(LC.MAT.f)[-1],
c("unit", "old_unit", "Treatment", "Genotype", "G..Alias", "Replicates")]
LC.MAT.f.t <- as.data.frame(t(LC.MAT.f))
colnames(LC.MAT.f.t) <- LC.MAT.f.t[1,]
LC.MAT.f.t = LC.MAT.f.t[-1,]
ncol(LC.MAT.f.t)
meta.LCDF <- meta.d.LCmat[order(match(meta.d.LCmat$unit, rownames(LC.MAT.f.t))), ] # reorder rows of 'meta.d.sp' according to rownames/unit of LC.MAT.f.t
LC.MAT.raw <- as.data.frame(cbind(meta.LCDF, LC.MAT.f.t))
ncol(LC.MAT.raw)
save(LC.MAT.raw, file = paste(opPATH.obj, "LC.MAT.raw.RData", sep = ""))
load(file = paste(opPATH.obj, "LC.MAT.raw.RData", sep = ""))
# TS 1343 ?
write.table(LC.MAT.raw, paste0(opPATH, "OP-1","_weight_raw.csv"), sep = ";", row.names = F) # OP-1 : RAW WEIGHT DATA BEFORE FILTERING
imputed.DF.final <- curateRawLC(x = LC.MAT.f, y = meta.LCDF, z= avg_wgt) ## +/- 30 % DONE
ncol(imputed.DF.final)-6 # 6 col of metadata, others are TS :  1536 problem it should be lower without irrigation /only measurement dates
df_imputed.DF.final = as.data.frame(t(imputed.DF.final))
TS_df = rownames(df_imputed.DF.final)[7:nrow(df_imputed.DF.final)] #
Date = t(c(NA, NA,NA,NA,NA,NA,rownames(df_imputed.DF.final)[7:nrow(df_imputed.DF.final)]))
Date = as.Date(Date)
df_imputed.DF.final$Date= Date
df_imputed.DF.final <- df_imputed.DF.final[!(df_imputed.DF.final$Date) %in% irrg.dts, ]
df_imputed.DF.final <- df_imputed.DF.final[, setdiff(colnames(df_imputed.DF.final), "Date")]
nrow(df_imputed.DF.final) -6 ## ok ! TS without irrigation match with imputed.DF.final !
imputed.DF.final = t(df_imputed.DF.final)
imputed.DF.final = as.data.frame(imputed.DF.final)
write.table(LC.MAT.raw, paste0(opPATH, "OP-2","_weight_imputed_cleaned1.csv"), sep = ";", row.names = F)
save(imputed.DF.final, file = paste(opPATH.obj, "imputed.DF.final.RData", sep = ""))
load(file = paste(opPATH.obj, "imputed.DF.final.RData", sep = ""))
# Outliers detection post curateRawLC
print("outlier WEIGHT detection AFTER filtering")
check_for_negative_values(imputed.DF.final) ##imputed.DF.final should not contain negative values
max_df=as.data.frame(colMax(imputed.DF.final[7:ncol(imputed.DF.final)]))
max(max_df[1:nrow(max_df),], na.rm = TRUE)  ##max of imputed.DF.final should not be an outlier value
print("Dataset should not contain negative weights, and maximum weight should not be an outlier")
# Identify the highly extreme valued sectors #
err.sec.info <- filterLCExtremeCols(x = imputed.DF.final, y = meta.LCDF)
err.sec.nm <- err.sec.info$err.sec.NM
err.sec.meta <- err.sec.info$err.sec.META
write.table(err.sec.meta, paste0(opPATH, "OP-3","_weight_outliers_LC_removed.csv"), sep = ";", row.names = F)
# Remove the err.cols i.e. sectors with extreme values
impData.errSEC.rmvd <- imputed.DF.final[!imputed.DF.final$unit %in% err.sec.nm, ]
save(impData.errSEC.rmvd, file = paste(opPATH.obj, "impData.errSEC.rmvd.RData", sep = ""))
load(file = paste(opPATH.obj, "impData.errSEC.rmvd.RData", sep = ""))
write.table(err.sec.meta, paste0(opPATH, "OP-4","_weight_imputed_cleaned2.csv"), sep = ";", row.names = F)
# Now, the weight profile should be cleaned. Verify on  LC
print("Plot the weight data after filtering. cleaned weights (weight outliers must be removed)")
weight_profile_output = draw_weight_cleaned(data=impData.errSEC.rmvd, path = path)
print("Generate ETr profiles with cleaned weight data")
et.vals <- getETr(x = impData.errSEC.rmvd)
save(et.vals, file = paste(opPATH.obj, "et.vals.RData", sep = ""))
load(file = paste(opPATH.obj, "et.vals.RData", sep = ""))
et.obs <- et.vals$obsETr_core
ETr_Meta <- et.vals$obsETr_meta
save(ETr_Meta, file = paste(opPATH.obj, "ETr_Meta.RData", sep = ""))
load(file = paste(opPATH.obj, "ETr_Meta.RData", sep = ""))
# Convert ETr in grams to mm (Y/N) #
print(" Would you like to convert the evapotranspiration data (currently in grams) into mm? Required : YES or NO")
print("you'll need to indicate which platform you're working on. Required : IRD or ICRISAT")
ETr_F <- convETr(x = ETr_Meta)
save(ETr_F , file = paste(opPATH.obj,  "ETr_F.RData", sep = ""))
load(file = paste(opPATH.obj, "ETr_F.RData", sep = ""))
ncol(ETr_F)-6 # n TS
#  Draw  profile of a LC  (weight/ETr) to follow the data cleaning process (2-ETr_F).
print("Plot raw evapotranspiration values after conversion grams/mm")
ET_profile_output = draw_ET_raw(data=ETr_F)
write.table(ETr_F, paste0(opPATH,  "OP-6_ETr_raw_after_conversion.csv"), col.names = TRUE, row.names = FALSE, sep = ";", dec = ".")
print(' Stage-II: Process Weather data to obtain ETref + filter ETr based on ETref ')
wthr.DFagg15min <- allData$climate
nrow(wthr.DFagg15min)
# wthr.DFagg15min$Date <- lubridate::ymd(wthr.DFagg15min$Date) #
# wthr.DFagg15min <- wthr.DFagg15min[wthr.DFagg15min$Date>=firstDate &
#                                      wthr.DFagg15min$Date<=lastDate,]
#
#
# # wthr.DFagg15min <- wthr.DFagg15min[,-1]
#
# # Create empty base matrix for weather variables
# end.seq_hhmm  <- '23:45'
#
# if (seq_by == '15'){
#   end.seq_hhmm  <- '23:45'
# } else if(seq_by == '30'){
#   end.seq_hhmm  <- '23:30'
# } else if(seq_by == '45'){
#   end.seq_hhmm  <- '23:15'
# } else if(seq_by == '60'){
#   end.seq_hhmm  <- '23:00'}
#
# TS_base<-as.data.frame(as.character(seq(ymd_hm(paste0(firstDate," ",'00:00')),
#                                         ymd_hm(paste0(lastDate," ",end.seq_hhmm)),
#                                         by = paste0(seq_by, " ", "mins"))))
# names(TS_base)[1]<-c("int.val")
# #
# time = as.data.frame(c(str_split( TS_base$int.val, " ")))
#
# time = time[-1,]
# time = t(time)
#
# ## pb at 00:00:00, no hour created !
#
#
# TS_base[,2] = time
# colnames(TS_base) =c("int.val", "time")
# TS_base = TS_base[,1:2]
#
# for (i in 1:nrow(TS_base)) {
#   if ((TS_base$time[i] =="00:15:00" )==TRUE){
#     TS_base$time[i-1] = "00:00:00"  } }
#
# # Since, the hms values slightly differ in the orginal dataset than the ideal 15min interval values,
# # replace them with the TS_base strftime (hms) values
#
# hms.ts.base<-unique(TS_base$time)
# names(hms.ts.base)<-c("time")
# #
# print("Climate matrix timestamp mapping status")
# #
# # i<-nrow(wthr.DFagg15min)
# # pbar <- create_progress_bar('text')
# # pbar$init(i)
# # #
# # for(i in 1:nrow(wthr.DFagg15min))
# # {
# #   if(! wthr.DFagg15min$TS[i] %in% hms.ts.base)
# #   {
# #     j <- which.min(abs(chron(times=hms.ts.base) -
# #                          chron(times=format(wthr.DFagg15min$TS[i],format = "%H:%M:%S")))) # find which value in ts-base-vector is nearest to each-DP
# #
# #     # assign the nearest ts-base-vector value to that DP
# #     dd <- date(wthr.DFagg15min$TS[i])
# #     wthr.DFagg15min$TS[i] <- ymd_hms(paste0(dd, TS_base$time[j]))}
# #   pbar$step()
# # }
# #
# TS_ALL<-as.data.frame(as.character(seq(ymd_hm(paste0(firstDate," ",'00:00')),
#                                        ymd_hm(paste0(lastDate," ",end.seq_hhmm)),
#                                        by = paste0(seq_by, " mins"))))
#  names(TS_ALL)[1]<-c("TS.n") # MUST be the same as in original data set m.lc.df
#
#
# ## pb at 00:00:00, no hour created !
# for (i in 1:nrow(TS_ALL)) {
#   if ((str_ends(TS_ALL$TS.n[i], "00:15:00"))==TRUE){
#     TS_ALL$TS.n[i-1] = "00:00:00"  } }
############## to be adapted for IRD and ICRISAT##############
# wthr.DFagg15min =  wthr.DFagg15min[!as.Date(wthr.DFagg15min$Date) %in% irrg.dts, ]
TS_weather = ymd_hms(paste (wthr.DFagg15min$Date, wthr.DFagg15min$TS)) ## TS kept after irrigation
length(TS_weather)
TS_weather = as.POSIXct(TS_weather)
head(TS_weather)
save(TS_weather, file =  paste(opPATH.obj,  "TS_weather.RData", sep = ""))
load(file = paste(opPATH.obj,  "TS_weather.RData", sep = "")) ## TS without irrigation, only for
wthr.DFagg15min$TS <- TS_weather
# # create empty dataframe to store all values
Wthr.MAT <- as.data.frame(matrix(nrow = length(TS_weather),
ncol = 2 ))
Wthr.MAT[ ,1] <- date(TS_weather); names(Wthr.MAT)[1] <- "Date"
Wthr.MAT[ ,2] <- (TS_weather); names(Wthr.MAT)[2] <- "TS"
#
# colnames(Wthr.MAT)[3:ncol(Wthr.MAT)] <- names(wthr.DFagg15min)[3:ncol(wthr.DFagg15min)]
Wthr.MAT <- Wthr.MAT[, !duplicated(names(Wthr.MAT))]
wthr.DFagg15min <- wthr.DFagg15min[, !duplicated(names(wthr.DFagg15min))]
#
# wthr.DFagg15min$TS = as.POSIXct(wthr.DFagg15min$TS)
nrow( wthr.DFagg15min )
nrow( Wthr.MAT )
wthr.DFagg15min <- wthr.DFagg15min[!apply(wthr.DFagg15min, 1, function(row) all(is.na(row))), ]
Wthr.MAT <- Wthr.MAT[!apply(Wthr.MAT, 1, function(row) all(is.na(row))), ]
df <- merge(x = Wthr.MAT, y = wthr.DFagg15min, by = "TS", all.x = TRUE)
nrow(df) == length(TS_weather)
colnames(df)
df <- df [c("TS" ,  "Temp",   "RH"  ,   "VPD"   , "SR"    , "WS")]
#
df <- df[!duplicated(df[c("TS")]),]
# colnames(df.new)[2] <- names(wthr.DFagg15min)[1]
#
etrDTS <- as.data.frame(colnames(ETr_F)[7:ncol(ETr_F)])
names(etrDTS) <- "TS"
etrDTS$TS <- ymd_hms(etrDTS$TS)
# df.new$Temp <- if(sum(is.na(df.new$Temp))>0){df.new$Temp<-na.aggregate.default(df.new$Temp)}
# df.new$RH <- if(sum(is.na(df.new$RH))>0){df.new$RH<-na.aggregate.default(df.new$RH)}
# df.new$SR <- if(sum(is.na(df.new$SR))>0){df.new$SR<-na.aggregate.default(df.new$SR)}
# df.new$WS <- if(sum(is.na(df.new$WS))>0){df.new$WS<-na.aggregate.default(df.new$WS)}
wthr.DFagg15min.filt <- df
# Compute VPD and insert into the weather DF #
SVP <- 610.7*(10^(7.5*wthr.DFagg15min.filt$Temp/(237.3+wthr.DFagg15min.filt$Temp)))
VPD <- ((1 - (wthr.DFagg15min.filt$RH/100))*SVP)/1000
wthr.DFagg15min.filt$VPD <- VPD
et.obs <- ETr_F
save(et.obs, file = paste(opPATH.obj,  "et.obs.RData", sep = ""))
col <- colnames(et.obs)[7:ncol(et.obs)]
utc_times <- as.POSIXct(col, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")
new_names <- format(utc_times, format = "%Y-%m-%d %H:%M:%S UTC", tz = "UTC")
colnames(et.obs)[7:ncol(et.obs)] <- new_names
# Calculate Penman Monteith ET #
wthr.df1 <- calculateETref(x=wthr.DFagg15min.filt)
max(wthr.df1$ETref) ## possible or outlier?
wthr.ETref.df <- as.data.frame(wthr.df1)
# select columns "Temp"  "RH"    "VPD"   "SR"    "WS"    "Tmax"  "Tmin"  "ETref"
empty.MAT.wthr.ETref  = as.data.frame(t(wthr.ETref.df[,c( "Temp",  "RH",    "VPD",   "SR",    "WS", "Tmax",  "Tmin",  "ETref")]))
colnames(empty.MAT.wthr.ETref) = wthr.ETref.df$TS
n <- 6  # add empty col
empty_cols <- as.data.frame(matrix(NA, nrow = nrow(empty.MAT.wthr.ETref), ncol = n))
empty.MAT.wthr.ETref <- cbind(empty_cols, empty.MAT.wthr.ETref)
colnames(empty.MAT.wthr.ETref)[1:6] <- colnames(et.obs)[1:6]
metad_col <- et.obs[1:6]
weather_ETr <- colnames(et.obs)[7:ncol(et.obs)]
weather_ETr <- trimws(weather_ETr)
TS_weather <- trimws(TS_weather)
# Supprimer " UTC" de weather_ETr
weather_ETr <- gsub(" UTC$", "", weather_ETr)
colnames(et.obs) <- gsub(" UTC$", "", colnames(et.obs) ) ## parfois UTC presnent/ parfois non
# Function to add "00:00:00" time to any date string that only has date (length == 10)
uniform_format <- function(dates) {
# If string length is exactly 10, append " 00:00:00" (start of day)
dates_fixed <- ifelse(nchar(dates) == 10, paste0(dates, " 00:00:00"), dates)
return(dates_fixed)
}
weather_ETr <- uniform_format(weather_ETr)
TS_weather = uniform_format(TS_weather)
matched_weather_cols <- intersect(weather_ETr, TS_weather)
length(matched_weather_cols)
nrow(metad_col)
et.obs.filtered <- et.obs[, c(matched_weather_cols)]
et.obs.filtered <- cbind(et.obs [1:6], et.obs.filtered)
et.obs = et.obs.filtered
ncol(et.obs)
ncol(empty.MAT.wthr.ETref)
colnames(empty.MAT.wthr.ETref) <- uniform_format(colnames(empty.MAT.wthr.ETref) )
colnames(et.obs)<- uniform_format(colnames(et.obs))
# et.obs <- et.obs[, colnames(empty.MAT.wthr.ETref)]
head(colnames(empty.MAT.wthr.ETref))
head(colnames(et.obs))
ncol(et.obs)
ncol(empty.MAT.wthr.ETref)
# Keep only common columns
common_cols <- intersect(names(et.obs), names(empty.MAT.wthr.ETref))
# Subset both data frames to those columns
df1_common <- empty.MAT.wthr.ETref[, common_cols, drop = FALSE]
df2_common <- et.obs[, common_cols, drop = FALSE]
# Bind the rows
wthr.ETref.ETobs <- rbind(df1_common, df2_common)
## save some parts of wthr.ETref.ETobs dataframe to reuse in the follwing steps
# (the format of wthr.ETref.ETobs will be use for the features extraction, hence you have to come back to this format each time)
metad_emptyrows= wthr.ETref.ETobs[,1:6]
save(metad_emptyrows, file =  paste(opPATH.obj,"metad_emptyrows.RData", sep = ""))
load(file =  paste(opPATH.obj,"metad_emptyrows.RData", sep = ""))
weather= wthr.ETref.ETobs[1:8,]
save(weather, file =  paste(opPATH.obj,"weather.RData", sep = ""))
load(file =  paste(opPATH.obj,"weather.RData", sep = ""))
save(wthr.ETref.ETobs, file =  paste(opPATH.obj,"wthr.ETref.ETobs.RData", sep = ""))
load(file =  paste(opPATH.obj,"wthr.ETref.ETobs.RData", sep = ""))
# Outliers detection
# nrow(check_for_negative_values(ETr_smth_metad[(9:nrow(ETr_smth_metad)),(7:ncol(ETr_smth_metad))]), n )
max_df=as.data.frame(colMax(ETr_smth_metad[(9:nrow(ETr_smth_metad)),(7:ncol(ETr_smth_metad))]))
packageVersion("rlang")
load(file = paste0(path, "./data/allData.RData"))
load(file = paste0(path, "./data/allData.RData"))
View(impData.errSEC.rmvd)
unique(impData.errSEC.rmvd$unit)
